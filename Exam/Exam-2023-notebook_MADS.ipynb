{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [Problem 1: Optimal taxation with government consumption](#toc1_)    \n",
    "- 2. [Problem 2: Labor adjustment costs](#toc2_)    \n",
    "- 3. [Problem 3: Global optimizer with refined multi-start](#toc3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a id='toc1_'></a>[Problem 1: Optimal taxation with government consumption](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Consider a worker choosing hours of labor, $L\\in[0,24]$, to maximize utility: \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "V(w,\\tau,G)&=\\max_{L\\in[0,24]}\\ln\\left(C^{\\alpha}G^{1-\\alpha}\\right)-\\nu\\frac{L^{2}}{2}\\\\&\\text{s.t.}\\\\&C=\\kappa+(1-\\tau)wL\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "* $C$ is *private* consumption with weight $\\alpha\\in(0,1)$.\n",
    "* $\\kappa > 0$ is the *free private* consumption component.\n",
    "* $C = (1-\\tau)wL$ is the *costly private* consumption component.\n",
    "* $w > 0 $ is the real wage.\n",
    "* $\\tau \\in (0,1)$ is the labor-income tax rate.\n",
    "* $G > 0 $ is *government* consumption with weight $1-\\alpha$.\n",
    "* $\\nu > 0$ is the disutility of labor scaling factor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The baseline parameters are:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\alpha &= 0.5\\\\\n",
    "\\kappa &= 1.0\\\\\n",
    "\\nu &= \\frac{1}{2\\cdot16^2} \\\\\n",
    "w &= 1.0 \\\\ \n",
    "\\tau &= 0.30 \\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Verify that the optimal labor supply choice is $L^{\\star}(\\tilde{w}) =\\frac{-\\kappa+\\sqrt{\\kappa^{2}+4\\frac{\\alpha}{\\nu}\\tilde{w}^2}}{2\\tilde{w}}$, where $\\tilde{w} = (1-\\tau)w$, for $G\\in\\left\\{1.0 , 2.0\\right\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sm\n",
    "\n",
    "alpha = sm.symbols('alpha')\n",
    "kappa = sm.symbols('kappa')\n",
    "nu = sm.symbols('nu')\n",
    "w = sm.symbols('w')\n",
    "wtilde = sm.symbols('omega')\n",
    "tau = sm.symbols('tau')\n",
    "C = sm.symbols('C')\n",
    "G = sm.symbols('G')\n",
    "L = sm.symbols('L')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{L^{2} \\nu}{2} + \\log{\\left(C^{\\alpha} G^{1 - \\alpha} \\right)}$"
      ],
      "text/plain": [
       "-L**2*nu/2 + log(C**alpha*G**(1 - alpha))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective = sm.log(C**alpha*G**(1-alpha))-nu*L**2/2\n",
    "objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle L \\omega + \\kappa = C$"
      ],
      "text/plain": [
       "Eq(L*omega + kappa, C)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraint = sm.Eq(kappa+wtilde*L, C)\n",
    "constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle L \\omega + \\kappa$"
      ],
      "text/plain": [
       "L*omega + kappa"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_from_con = sm.solve(constraint, C)\n",
    "C_from_con[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{L^{2} \\nu}{2} + \\log{\\left(G^{1 - \\alpha} \\left(L \\omega + \\kappa\\right)^{\\alpha} \\right)}$"
      ],
      "text/plain": [
       "-L**2*nu/2 + log(G**(1 - alpha)*(L*omega + kappa)**alpha)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_subs = objective.subs(C, C_from_con[0])\n",
    "objective_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{G^{1 - \\alpha} G^{\\alpha - 1} \\alpha \\omega}{L \\omega + \\kappa} - L \\nu$"
      ],
      "text/plain": [
       "G**(1 - alpha)*G**(alpha - 1)*alpha*omega/(L*omega + kappa) - L*nu"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foc = sm.diff(objective_subs, L)\n",
    "foc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{- \\kappa \\nu + \\sqrt{\\nu \\left(4 \\alpha \\omega^{2} + \\kappa^{2} \\nu\\right)}}{2 \\nu \\omega}$"
      ],
      "text/plain": [
       "(-kappa*nu + sqrt(nu*(4*alpha*omega**2 + kappa**2*nu)))/(2*nu*omega)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol = sm.solve(sm.Eq(foc,0), L)\n",
    "sol[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Illustrate how $L^{\\star}(\\tilde{w})$ depends on $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<lambdifygenerated-11>:2: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return 0.5*(-32.0*sqrt(omega**2 + 0.0009765625) - 1.0)/omega\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sympy as sm\n",
    "\n",
    "sol_func = sm.lambdify(args=(alpha, kappa, nu, wtilde),expr=sol[1])\n",
    "\n",
    "# Define the parameter values\n",
    "alpha = 0.5\n",
    "kappa = 1.0\n",
    "nu = 1 / (2 * 16 ** 2)\n",
    "w = 1.0\n",
    "tau = 0.30\n",
    "wtilde = 0.7\n",
    "\n",
    "# Define the symbols and equations\n",
    "wtilde = sm.symbols('omega')\n",
    "C = sm.symbols('C')\n",
    "G = sm.symbols('G')\n",
    "L = sm.symbols('L')\n",
    "\n",
    "objective = sm.log(C ** alpha * G ** (1 - alpha)) - nu * L ** 2 / 2\n",
    "constraint = sm.Eq(kappa + wtilde * L, C)\n",
    "\n",
    "# Solve for C in terms of w and substitute in the objective function\n",
    "C_from_con = sm.solve(constraint, C)\n",
    "objective_subs = objective.subs(C, C_from_con[0])\n",
    "\n",
    "# Compute the first-order condition and solve for L\n",
    "foc = sm.diff(objective_subs, L)\n",
    "sol = sm.solve(sm.Eq(foc, 0), L)\n",
    "\n",
    "# Convert the symbolic expression to a numerical function\n",
    "sol_fn = sm.lambdify(wtilde, sol[0])\n",
    "\n",
    "# Create an array of w values\n",
    "w_values = np.linspace(0, 10, 100)\n",
    "\n",
    "# Evaluate the solution function for each w value\n",
    "sol_values = sol_fn(w_values)\n",
    "\n",
    "# Plot the relationship between w and sol\n",
    "plt.plot(w_values, sol_values)\n",
    "plt.xlabel('w')\n",
    "plt.ylabel('sol')\n",
    "plt.title(\"Relationship between 'sol' and 'w'\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We now consider a government, who chooses $\\tau$ and spend all of the taxes on government consumption so:\n",
    "\n",
    "$$\n",
    "G = \\tau w L^{\\star}((1-\\tau)w)\n",
    "$$\n",
    "\n",
    "**Question 3:** Plot the implied $L$, $G$ and worker utility for a grid of $\\tau$-values.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Find the socially optimal tax rate $\\tau^{\\star}\\in(0,1)$ maximizing worker utility. Illustrate your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more general preference formulation for the worker is:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathcal{V}(w,\\tau,G)&=\\max_{L\\in[0,24]}\\frac{\\left[ \\left( \\alpha C^{\\frac{\\sigma-1}{\\sigma}}+(1-\\alpha) G^{\\frac{\\sigma-1}{\\sigma}} \\right)^{\\frac{\\sigma}{1-\\sigma} }\\right]^{1-\\rho}-1}{1-\\rho}- \\nu\\frac{L^{1+\\varepsilon}}{1+\\varepsilon},\\,\\,\\,\\varepsilon,\\rho,\\sigma>0,\\,\\,\\,\\rho,\\sigma\\neq1\\\\&\\text{s.t.}\\\\&C=\\kappa+(1-\\tau)wL\n",
    "\\end{align*}    \n",
    "$$\n",
    "\n",
    "Optimal labor supply is now $L^{\\star}(\\tilde{w},G)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions 5 and 6 must be answered with the general formulation, and for 2 different set of parameters:\n",
    "\n",
    "- Set 1:  $\\sigma = 1.001$, $\\rho = 1.001$ and $\\varepsilon = 1.0$.\n",
    "- Set 2:  $\\sigma = 1.5$, $\\rho = 1.5$ and $\\varepsilon = 1.0 $."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** Find the $G$ that solves $G = \\tau w L^{\\star}((1-\\tau)w,G)$ using the $\\tau$ found in question 4.\n",
    "\n",
    "*Hint: First write code that solves the worker problem for given values of $G$ and $\\tau$. Then find the correct G based on this.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6:** Find the socially optimal tax rate, $\\tau^{\\star}$, maximizing worker utility, while keeping $G = \\tau w L^{\\star}((1-\\tau)w,G)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a id='toc2_'></a>[Problem 2: Labor adjustment costs](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You own a hair salon. You employ hairdressers, $\\ell_t$, to produce haircuts, $y_t = \\ell_t$.\n",
    "\n",
    "The wage for each haridresser is $w$.\n",
    "\n",
    "The demand for haircuts implies that the price of haircuts you can charge is $p_t = \\kappa_t y_t^{-\\eta}$, where $\\kappa_t$ is a demand-shock and $\\eta \\in (0,1)$ measures the elasticity of demand.\n",
    "\n",
    "Profits are:\n",
    "\n",
    "$$\n",
    "\\Pi_t = p_t y_t - w \\ell_t = \\kappa_t \\ell_t^{1-\\eta} - w \\ell_t\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline parameters are:\n",
    "- $\\eta = 0.5$\n",
    "- $w = 1.0$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Verify numerically that $\\ell_{t}=\\left(\\frac{(1-\\eta)\\kappa_{t}}{w}\\right)^{\\frac{1}{\\eta}}$ maximises profits, for $\\kappa\\in\\left\\{1.0 , 2.0\\right\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now consider a *dynamic* version of the model.\n",
    "\n",
    "* The demand-shock is a so-called AR(1) in logs, \n",
    "\n",
    "$$\n",
    "\\log \\kappa_{t} = \\rho \\log \\kappa_{t-1} + \\epsilon_{t},\\,\\,\\, \\epsilon_{t+1} \\sim \\mathcal{N}(-0.5\\sigma_{\\epsilon}^2,\\sigma_{\\epsilon})\n",
    "$$\n",
    "\n",
    "* Any hiring or firing implies a fixed adjustment cost, $\\iota > 0 $.\n",
    "* Future profits are discounted with a monthly factor of $R \\in (0,1)$.\n",
    "\n",
    "The initial demand shock is $\\kappa_{-1} = 1$ and the planning horizon is 10 years, i.e. 120 months so $t \\in \\{0,1,2,\\dots,119\\}$. Initially you don't have any employees, $\\ell_{-1}=0$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The *ex post* value of the salon is *conditional* on the shock series is:\n",
    "\n",
    "$$\n",
    "h(\\epsilon_0,\\epsilon_1,\\dots,\\epsilon_{119}) = \\left[\\sum_{t=0}^{119}R^{-t}\\left[\\kappa_{t}\\ell_{t}^{1-\\eta}-w\\ell_{t}-\\boldsymbol{1}_{\\ell_{t}\\neq\\ell_{t-1}}\\iota\\right]\\right]\n",
    "$$\n",
    "\n",
    "The *ex ante* expected value of the salon can be approximated by\n",
    "\n",
    "$$\n",
    "H = \\mathbb{E}[h(\\epsilon_0,\\epsilon_1,\\dots,\\epsilon_{119})] \\approx \\frac{1}{K}\\sum_{k=0}^{K} h(\\epsilon_0^k,\\epsilon_1^k,\\dots,\\epsilon_{119}^k)\n",
    "$$\n",
    "\n",
    "where each $k\\in\\{0,1,\\dots,K-1\\}$ is a random shock series. Maximizing profitability means maximizing $H$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline parameters are: \n",
    "\n",
    "- $\\rho = 0.90$\n",
    "- $\\iota = 0.01$\n",
    "- $\\sigma_{\\epsilon} = 0.10$\n",
    "- $R = \\left(1+0.01\\right)^{1/12}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Calculate $H$ if the policy  $\\ell_{t}=\\left(\\frac{(1-\\eta)\\kappa_{t}}{w}\\right)^{\\frac{1}{\\eta}}$ from question 1 is followed. Choose $K$ so the approximation is good enough to not affect your results substantially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we consider policies on the form:\n",
    "\n",
    "$$\n",
    "\n",
    "\\ell_{t}=\\begin{cases}\n",
    "\\ell_t^{\\ast}  & \\text{if }\\left|\\ell_{t-1}-\\ell_t^{\\ast} \\right|>\\Delta\\\\\n",
    "\\ell_{t-1} & \\text{else }\n",
    "\\end{cases}\n",
    "\\\\\n",
    "\\text{where}\\,\\,\\ell_t^{\\ast} = \\left(\\frac{(1-\\eta)\\kappa_{t}}{w}\\right)^{\\frac{1}{\\eta}} \\\\\n",
    "\n",
    "$$\n",
    "With $\\Delta \\geq 0$ and $\\Delta = 0$ being the previous policy.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 3:** Calculate $H$ if the policy above was followed with $\\Delta = 0.05$. Does it improve profitability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Find the optimal $\\Delta$ maximizing $H$. Illustrate your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 5:** Suggest an alternative policy you believe might improve profitability. Implement and test your policy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. <a id='toc3_'></a>[Problem 3: Global optimizer with refined multi-start](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the Griewank function:\n",
    "\n",
    "$$ f(\\boldsymbol{x}) = \\sum^n_{i=1} \\frac{x^2_i}{4000}-\\prod^n_{i=1}\\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right)+1$$\n",
    "\n",
    "The **global minimum** of this function is $f(0,0) = 0$ (remember: $\\cos(0)=1$).<br>\n",
    "But the function also have a lot of **local minima**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def griewank(x):\n",
    "    return griewank_(x[0],x[1])\n",
    "    \n",
    "def griewank_(x1,x2):\n",
    "    A = x1**2/4000 + x2**2/4000\n",
    "    B = np.cos(x1/np.sqrt(1))*np.cos(x2/np.sqrt(2))\n",
    "    return A-B+1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **refined global optimizer with multi-start** is:\n",
    "\n",
    "1. Choose *bounds* for $\\mathbf{x}$ and *tolerance* $\\tau > 0$.\n",
    "2. Choose number of *warm-up iterations*, $\\underline{K} > 0$ and *maximum number of iterations*, $K > \\underline{K}$.\n",
    "3. In each iteration for $k \\in \\{0,1,\\dots,K-1\\}$:\n",
    "\n",
    "    A. Draw random $\\mathbf{x}^k$ uniformly within chosen bounds.\n",
    "\n",
    "    B. If $k < \\underline{K}$ go to step E.\n",
    "\n",
    "    C. Calculate $\\chi^k = 0.50\\cdot\\frac{2}{1+\\exp((k-\\underline{K})/100)}$  \n",
    "\n",
    "    D. Set $\\mathbf{x}^{k0} = \\chi^k \\mathbf{x}^k + (1-\\chi^k)\\mathbf{x}^{\\ast} $\n",
    "\n",
    "    E. Run optimizer with $\\mathbf{x}^{k0}$ as initial guess and $\\mathbf{x}^{k\\ast}$ as result.\n",
    "\n",
    "    F. Set $\\mathbf{x}^{\\ast} = \\mathbf{x}^{k\\ast}$ if $k = 0$ or $f(\\mathbf{x}^{k\\ast}) < f(\\mathbf{x}^{\\ast})$\n",
    "\n",
    "    G. If $f(\\mathbf{x}^{\\ast}) < \\tau$ go to step 4.\n",
    "\n",
    "4. Return the result $\\mathbf{x}^{\\ast}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As settings we choose:\n",
    "\n",
    "* $x_1,x_2 \\in  [-600,600]$\n",
    "* $\\tau = 10^{-8}$\n",
    "* $\\underline{K}=10$\n",
    "* $K=1000$\n",
    "\n",
    "The optimizer in Step 3.E is `BFGS` with a tolerance of $\\tau$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Implement the refined global optimizer with multi-start. Illustrate how the effective initial guesses $\\mathbf{x}^{k0}$ vary with the iteration counter $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: x_k0 = [ 354.29619466 -142.74725006], f(x_k0) = 38.17589412415801\n",
      "Iteration 1: x_k0 = [-205.29996633  404.80553482], f(x_k0) = 52.07574583361529\n",
      "Iteration 2: x_k0 = [ 574.89189515 -217.55474206], f(x_k0) = 94.46324186867706\n",
      "Iteration 3: x_k0 = [-100.11083355  401.13175492], f(x_k0) = 43.164410362750985\n",
      "Iteration 4: x_k0 = [-279.10502547   37.13828827], f(x_k0) = 21.196408949376963\n",
      "Iteration 5: x_k0 = [ 362.67704181 -127.13790111], f(x_k0) = 37.86190410616047\n",
      "Iteration 6: x_k0 = [ 524.32665467 -374.59019043], f(x_k0) = 105.33675940837418\n",
      "Iteration 7: x_k0 = [369.47377425 530.7039148 ], f(x_k0) = 105.59069433118853\n",
      "Iteration 8: x_k0 = [255.34696997 581.91550929], f(x_k0) = 101.31988115870571\n",
      "Iteration 9: x_k0 = [-57.68734361 375.26547871], f(x_k0) = 36.991272193296155\n",
      "Iteration 10: x_k0 = [-249.99894661  139.15065073], f(x_k0) = 21.59423779082545\n",
      "Iteration 11: x_k0 = [-157.80211173  181.89351061], f(x_k0) = 16.23375666139699\n",
      "Iteration 12: x_k0 = [-94.55890636 271.10908467], f(x_k0) = 22.560302198453112\n",
      "Iteration 13: x_k0 = [-56.24984386  63.43527227], f(x_k0) = 2.1831205479284286\n",
      "Iteration 14: x_k0 = [-110.77592868   13.69181113], f(x_k0) = 3.4549738795624587\n",
      "Iteration 15: x_k0 = [ 58.05274744 211.12931367], f(x_k0) = 12.982075649538803\n",
      "Iteration 16: x_k0 = [-141.77508245   40.24295579], f(x_k0) = 5.525336945805588\n",
      "Iteration 17: x_k0 = [-224.87318496 -115.05786366], f(x_k0) = 16.717605799711002\n",
      "Iteration 18: x_k0 = [-306.52262887 -248.23701863], f(x_k0) = 39.69574440763118\n",
      "Iteration 19: x_k0 = [-294.49703574   13.04459634], f(x_k0) = 23.39840332659064\n",
      "Iteration 20: x_k0 = [ 229.62685749 -172.70988329], f(x_k0) = 20.756030190446037\n",
      "Iteration 21: x_k0 = [  58.73147878 -139.95398654], f(x_k0) = 6.760415653687144\n",
      "Iteration 22: x_k0 = [-37.57148514 271.53432959], f(x_k0) = 20.71158086445092\n",
      "Iteration 23: x_k0 = [-137.15915099  278.49652377], f(x_k0) = 25.354803329990833\n",
      "Iteration 24: x_k0 = [ 51.03614311 -11.98329119], f(x_k0) = 2.103634951491669\n",
      "Iteration 25: x_k0 = [-137.20606526   43.66871827], f(x_k0) = 5.7364829482169\n",
      "Iteration 26: x_k0 = [-67.36621155 237.3576796 ], f(x_k0) = 16.177470691354287\n",
      "Iteration 27: x_k0 = [  71.15622276 -225.08486082], f(x_k0) = 14.710896027970508\n",
      "Iteration 28: x_k0 = [-133.73170722  -79.94140736], f(x_k0) = 7.281039528955807\n",
      "Iteration 29: x_k0 = [-219.9534709  -127.20209158], f(x_k0) = 17.538298396828313\n",
      "Iteration 30: x_k0 = [-125.22927694 -229.65020167], f(x_k0) = 17.596808234303225\n",
      "Iteration 31: x_k0 = [-91.56953663 -59.45258896], f(x_k0) = 3.65460001119146\n",
      "Iteration 32: x_k0 = [151.81253072 -52.63562215], f(x_k0) = 6.98723456418263\n",
      "Iteration 33: x_k0 = [222.10501259  59.15911238], f(x_k0) = 13.888122058461374\n",
      "Iteration 34: x_k0 = [-76.14237726 245.66269221], f(x_k0) = 17.981368512274546\n",
      "Iteration 35: x_k0 = [257.30670157  15.55480154], f(x_k0) = 17.608993924236497\n",
      "Iteration 36: x_k0 = [214.87453349  99.31433499], f(x_k0) = 14.867029219741253\n",
      "Iteration 37: x_k0 = [  2.0462409  -42.71245204], f(x_k0) = 1.6171546579345795\n",
      "Iteration 38: x_k0 = [ -7.56421211 -26.84739912], f(x_k0) = 0.9113462673012913\n",
      "Iteration 39: x_k0 = [ -99.94650791 -190.09557939], f(x_k0) = 13.184808471823432\n",
      "Iteration 40: x_k0 = [-139.47800681  -61.13328389], f(x_k0) = 6.566677284355189\n",
      "Iteration 41: x_k0 = [  3.43603238 -57.82095369], f(x_k0) = 0.882766138396035\n",
      "Iteration 42: x_k0 = [ -35.66406552 -239.92894073], f(x_k0) = 16.15718815969867\n",
      "Iteration 43: x_k0 = [-173.06869355 -249.2227655 ], f(x_k0) = 24.934619755718938\n",
      "Iteration 44: x_k0 = [-95.29024491 -41.37053587], f(x_k0) = 3.9791254791885216\n",
      "Iteration 45: x_k0 = [-65.37373622 156.8196575 ], f(x_k0) = 7.724676999331523\n",
      "Iteration 46: x_k0 = [ -89.62893513 -132.74824921], f(x_k0) = 7.5005852099393415\n",
      "Iteration 47: x_k0 = [ 161.56996092 -246.54741519], f(x_k0) = 22.717545482310047\n",
      "Iteration 48: x_k0 = [  28.48367723 -158.01349496], f(x_k0) = 7.644856429528412\n",
      "Iteration 49: x_k0 = [-150.51231752  191.43538938], f(x_k0) = 16.74873928864063\n",
      "Iteration 50: x_k0 = [-192.54913144  -65.08601877], f(x_k0) = 11.05076995183999\n",
      "Iteration 51: x_k0 = [151.17654328  52.66605652], f(x_k0) = 6.57433275036507\n",
      "Iteration 52: x_k0 = [-36.54953872 213.32577115], f(x_k0) = 12.302525450432187\n",
      "Iteration 53: x_k0 = [ 136.59817288 -249.43436289], f(x_k0) = 21.27419559492307\n",
      "Iteration 54: x_k0 = [-126.08167224   61.21098132], f(x_k0) = 5.2116041501763375\n",
      "Iteration 55: x_k0 = [-37.060951   180.92179462], f(x_k0) = 10.041845792835145\n",
      "Iteration 56: x_k0 = [49.87806376 35.92252607], f(x_k0) = 1.0518054884408292\n",
      "Iteration 57: x_k0 = [-183.30643515  164.16463904], f(x_k0) = 16.591056451934605\n",
      "Iteration 58: x_k0 = [ 27.03630286 124.25470877], f(x_k0) = 5.367466929591613\n",
      "Iteration 59: x_k0 = [-207.60213928  -95.66778757], f(x_k0) = 13.963207467318998\n",
      "Iteration 60: x_k0 = [-178.98768162 -164.29626633], f(x_k0) = 14.762949517607286\n",
      "Iteration 61: x_k0 = [ 69.26898437 107.92452409], f(x_k0) = 4.509630568014465\n",
      "Iteration 62: x_k0 = [ 141.93546018 -235.56846431], f(x_k0) = 19.066241895870768\n",
      "Iteration 63: x_k0 = [-171.76746458 -214.82069772], f(x_k0) = 20.14813858882474\n",
      "Iteration 64: x_k0 = [-31.00329058  21.89504883], f(x_k0) = 2.2529568602757677\n",
      "Iteration 65: x_k0 = [113.74548717 113.9374149 ], f(x_k0) = 7.12938364137234\n",
      "Iteration 66: x_k0 = [-219.95653829 -201.88853455], f(x_k0) = 23.469425638310263\n",
      "Iteration 67: x_k0 = [ 186.13122827 -223.99198115], f(x_k0) = 22.390444920464056\n",
      "Iteration 68: x_k0 = [-11.67283664  63.7165101 ], f(x_k0) = 1.7492802174755036\n",
      "Iteration 69: x_k0 = [-155.70330245 -134.75513272], f(x_k0) = 11.502540888415897\n",
      "Iteration 70: x_k0 = [-212.15261292  -16.60553556], f(x_k0) = 12.25664325905848\n",
      "Iteration 71: x_k0 = [-70.61606241 111.87352783], f(x_k0) = 5.4343956513373195\n",
      "Iteration 72: x_k0 = [-25.24655405 132.42410151], f(x_k0) = 4.728923504637221\n",
      "Iteration 73: x_k0 = [ -88.68369012 -138.43137748], f(x_k0) = 8.41860198428766\n",
      "Iteration 74: x_k0 = [168.62671551  60.28855926], f(x_k0) = 8.903611391470939\n",
      "Iteration 75: x_k0 = [-44.80462567 128.89145688], f(x_k0) = 6.335242886852152\n",
      "Iteration 76: x_k0 = [121.72023537 -74.09313999], f(x_k0) = 5.709702559077324\n",
      "Iteration 77: x_k0 = [-137.13306717  154.979671  ], f(x_k0) = 12.131663097704115\n",
      "Iteration 78: x_k0 = [-37.39283527 174.55036978], f(x_k0) = 9.556475908607663\n",
      "Iteration 79: x_k0 = [ 136.10372201 -117.04817997], f(x_k0) = 9.302778024698972\n",
      "Iteration 80: x_k0 = [ 97.65543707 -84.11000419], f(x_k0) = 4.2102739989354685\n",
      "Iteration 81: x_k0 = [ 39.7764126  -46.99744934], f(x_k0) = 1.829829367799956\n",
      "Iteration 82: x_k0 = [-195.2369664 -127.0271921], f(x_k0) = 14.816701746290452\n",
      "Iteration 83: x_k0 = [-194.81174861 -187.45486317], f(x_k0) = 18.449950953095115\n",
      "Iteration 84: x_k0 = [-163.13248844  150.3462143 ], f(x_k0) = 12.451197130905213\n",
      "Iteration 85: x_k0 = [  5.2812794  -27.77649385], f(x_k0) = 0.8212293740117709\n",
      "Iteration 86: x_k0 = [140.11823751 114.56553681], f(x_k0) = 9.433937867455107\n",
      "Iteration 87: x_k0 = [-104.67519379   62.05265713], f(x_k0) = 5.237007145360874\n",
      "Iteration 88: x_k0 = [  86.16526409 -135.8307236 ], f(x_k0) = 7.417347437612064\n",
      "Iteration 89: x_k0 = [ 62.04564893 116.28662392], f(x_k0) = 4.739120301946214\n",
      "Iteration 90: x_k0 = [ 69.70871108 -43.81171792], f(x_k0) = 1.9434727180519353\n",
      "Iteration 91: x_k0 = [-65.0489216  121.33829297], f(x_k0) = 5.401204843398984\n",
      "Iteration 92: x_k0 = [-106.22522256 -162.94308413], f(x_k0) = 10.893215080255061\n",
      "Iteration 93: x_k0 = [121.53068028  91.91022275], f(x_k0) = 6.5007467427701995\n",
      "Iteration 94: x_k0 = [ 122.14498448 -167.94453585], f(x_k0) = 12.534728562823151\n",
      "Iteration 95: x_k0 = [139.57521424  14.17008589], f(x_k0) = 6.105806744831969\n",
      "Iteration 96: x_k0 = [  1.9253815  -31.60798106], f(x_k0) = 0.925634519128812\n",
      "Iteration 97: x_k0 = [85.93433407 79.63071816], f(x_k0) = 4.862065467090234\n",
      "Iteration 98: x_k0 = [-48.38140386  -5.67584992], f(x_k0) = 1.3949530194112203\n",
      "Iteration 99: x_k0 = [120.9108984  128.45502027], f(x_k0) = 8.818926349089736\n",
      "Iteration 100: x_k0 = [-67.14143735 147.70091779], f(x_k0) = 7.298852626940445\n",
      "Iteration 101: x_k0 = [-36.0670847  -22.21601556], f(x_k0) = 1.387403966989934\n",
      "Iteration 102: x_k0 = [-153.13825736   76.1353572 ], f(x_k0) = 7.678193407996632\n",
      "Iteration 103: x_k0 = [ 56.31490493 123.73423837], f(x_k0) = 4.7536260086363376\n",
      "Iteration 104: x_k0 = [-27.05738667 128.38276326], f(x_k0) = 4.975283377873769\n",
      "Iteration 105: x_k0 = [ 150.08865444 -179.55492602], f(x_k0) = 14.48898414891924\n",
      "Iteration 106: x_k0 = [-44.68366262 -28.28327786], f(x_k0) = 1.3868944254505964\n",
      "Iteration 107: x_k0 = [ 82.37992938 -98.92345688], f(x_k0) = 4.628756042047777\n",
      "Iteration 108: x_k0 = [-94.50133273  38.76959244], f(x_k0) = 4.239905430636418\n",
      "Iteration 109: x_k0 = [-37.24316818 114.15342925], f(x_k0) = 4.091603125412396\n",
      "Iteration 110: x_k0 = [ 1.43623111e+02 -3.07097071e-02], f(x_k0) = 5.527753153108985\n",
      "Iteration 111: x_k0 = [-47.48399971  65.90131328], f(x_k0) = 1.8394317363346564\n",
      "Iteration 112: x_k0 = [-41.63061236 -97.29654166], f(x_k0) = 4.46898992642679\n",
      "Iteration 113: x_k0 = [ -18.77967785 -162.39945721], f(x_k0) = 7.846032040391871\n",
      "Iteration 114: x_k0 = [ 118.09078937 -155.10169398], f(x_k0) = 10.766893261989738\n",
      "Iteration 115: x_k0 = [ 36.72740233 -70.17392343], f(x_k0) = 2.1177257822771915\n",
      "Iteration 116: x_k0 = [-64.44053303  -2.24023793], f(x_k0) = 2.038896860738798\n",
      "Iteration 117: x_k0 = [-102.95826955  -97.82720737], f(x_k0) = 6.79687624858346\n",
      "Iteration 118: x_k0 = [45.53680049 26.85019914], f(x_k0) = 1.6824924137872936\n",
      "Iteration 119: x_k0 = [ 60.73666634 -58.95955303], f(x_k0) = 2.4608471662000984\n",
      "Iteration 120: x_k0 = [ 107.90970757 -123.73809134], f(x_k0) = 7.33066726533608\n",
      "Iteration 121: x_k0 = [ 29.34704565 -93.8460409 ], f(x_k0) = 2.9744404158755353\n",
      "Iteration 122: x_k0 = [81.40959063 18.51927201], f(x_k0) = 1.9108760123238682\n",
      "Iteration 123: x_k0 = [ -9.49781434 -11.66167888], f(x_k0) = 0.6754667824292542\n",
      "Iteration 124: x_k0 = [113.82204645  47.81880231], f(x_k0) = 5.361121468304825\n",
      "Iteration 125: x_k0 = [-143.09385534  -75.864306  ], f(x_k0) = 7.7044041969185075\n",
      "Iteration 126: x_k0 = [-28.89047726  68.59757754], f(x_k0) = 2.23184418935774\n",
      "Iteration 127: x_k0 = [100.97658785 131.25606821], f(x_k0) = 7.7345952133953935\n",
      "Iteration 128: x_k0 = [ -74.53345952 -122.53029948], f(x_k0) = 5.982834175242285\n",
      "Iteration 129: x_k0 = [ 116.40723044 -108.15322512], f(x_k0) = 7.778647130361076\n",
      "Iteration 130: x_k0 = [-120.72734877  -35.48081806], f(x_k0) = 4.736609753876188\n",
      "Iteration 131: x_k0 = [-16.40715339  90.32142667], f(x_k0) = 3.497500235314516\n",
      "Iteration 132: x_k0 = [56.81174404 44.4409478 ], f(x_k0) = 1.3350839209201482\n",
      "Iteration 133: x_k0 = [ 88.49273539 -62.61416884], f(x_k0) = 3.1108424517283995\n",
      "Iteration 134: x_k0 = [-83.78346427  90.18508938], f(x_k0) = 5.087610826830858\n",
      "Iteration 135: x_k0 = [ 59.73674639 -82.14527725], f(x_k0) = 3.6130196225672355\n",
      "Iteration 136: x_k0 = [ 38.05713009 -67.67427864], f(x_k0) = 3.2055555777720857\n",
      "Iteration 137: x_k0 = [-61.19954759 -71.98913447], f(x_k0) = 3.28131433080423\n",
      "Iteration 138: x_k0 = [37.07406673 58.78221545], f(x_k0) = 2.814660261728799\n",
      "Iteration 139: x_k0 = [ 46.03233495 -30.26321324], f(x_k0) = 1.376026455185532\n",
      "Iteration 140: x_k0 = [ -49.71480704 -102.87612526], f(x_k0) = 5.016554107826232\n",
      "Iteration 141: x_k0 = [-109.77755182   78.81088024], f(x_k0) = 6.236294268737961\n",
      "Iteration 142: x_k0 = [-57.61701152  -7.32584601], f(x_k0) = 1.6262072020888185\n",
      "Iteration 143: x_k0 = [18.74280211 68.61128035], f(x_k0) = 2.441912712348494\n",
      "Iteration 144: x_k0 = [-57.36639849  85.33821622], f(x_k0) = 4.186571388867268\n",
      "Iteration 145: x_k0 = [ -6.94618546 -86.58942769], f(x_k0) = 2.9125659730011355\n",
      "Iteration 146: x_k0 = [ 14.48523853 -49.12759357], f(x_k0) = 1.320317924191785\n",
      "Iteration 147: x_k0 = [ 36.26649375 -38.00425214], f(x_k0) = 1.7131342007551442\n",
      "Iteration 148: x_k0 = [ 18.92391017 -81.01085387], f(x_k0) = 1.9902073691511695\n",
      "Iteration 149: x_k0 = [-58.69312658 -20.46625596], f(x_k0) = 1.7876842902666028\n",
      "Iteration 150: x_k0 = [ 56.65406758 -35.21031686], f(x_k0) = 1.1453115872769866\n",
      "Iteration 151: x_k0 = [  90.22290383 -123.60516509], f(x_k0) = 7.391425762871487\n",
      "Iteration 152: x_k0 = [-93.65551308  14.6145092 ], f(x_k0) = 3.7559431034307256\n",
      "Iteration 153: x_k0 = [ 93.68801741 -99.08656757], f(x_k0) = 5.155815262782489\n",
      "Iteration 154: x_k0 = [ 73.69876942 -14.09644466], f(x_k0) = 2.2977004167928667\n",
      "Iteration 155: x_k0 = [37.93269623  9.04900146], f(x_k0) = 0.41382385062176863\n",
      "Iteration 156: x_k0 = [ -89.3815379  -119.41945069], f(x_k0) = 6.704790990028714\n",
      "Iteration 157: x_k0 = [ -1.24343477 -28.09285288], f(x_k0) = 1.0280594595310508\n",
      "Iteration 158: x_k0 = [ 1.68549344 -4.39611603], f(x_k0) = 0.8911584541671844\n",
      "Iteration 159: x_k0 = [-99.46610919  94.6506564 ], f(x_k0) = 5.993118635857742\n",
      "Iteration 160: x_k0 = [-8.10260978 -1.21019578], f(x_k0) = 1.1781208615056142\n",
      "Iteration 161: x_k0 = [-23.2676768  -13.08168399], f(x_k0) = 0.8925005826422239\n",
      "Iteration 162: x_k0 = [12.53806342 17.08411253], f(x_k0) = 0.22845021128275045\n",
      "Iteration 163: x_k0 = [ 35.17689013 -63.03747428], f(x_k0) = 2.978497648702646\n",
      "Iteration 164: x_k0 = [-12.09792078 -65.43013402], f(x_k0) = 2.69050278033915\n",
      "Iteration 165: x_k0 = [-77.74728937  64.32683521], f(x_k0) = 3.592754249739471\n",
      "Iteration 166: x_k0 = [-60.30668217  75.32492963], f(x_k0) = 2.520214028057534\n",
      "Iteration 167: x_k0 = [ 58.02020339 -28.66242787], f(x_k0) = 2.031871210663785\n",
      "Iteration 168: x_k0 = [ 2.3937076  13.82368103], f(x_k0) = 0.3605349640469825\n",
      "Iteration 169: x_k0 = [30.27891187 80.79354855], f(x_k0) = 2.509763000109182\n",
      "Iteration 170: x_k0 = [-13.66513096  87.61941493], f(x_k0) = 2.674711980999777\n",
      "Iteration 171: x_k0 = [ 0.19113109 65.57277053], f(x_k0) = 2.7886599142136284\n",
      "Iteration 172: x_k0 = [-20.1060583  -38.24125763], f(x_k0) = 1.5689164913690823\n",
      "Iteration 173: x_k0 = [-30.89528569   2.59939515], f(x_k0) = 1.46941150952712\n",
      "Iteration 174: x_k0 = [-61.1259029  -68.99436836], f(x_k0) = 3.136488265614223\n",
      "Iteration 175: x_k0 = [ 85.1326388  -40.26016578], f(x_k0) = 2.2825166149932716\n",
      "Iteration 176: x_k0 = [  2.9070161  -13.27687143], f(x_k0) = 0.0742204604618606\n",
      "Iteration 177: x_k0 = [-20.45014392  71.49507134], f(x_k0) = 2.4109889523689687\n",
      "Iteration 178: x_k0 = [-56.94534689 -73.93938379], f(x_k0) = 3.575949064119507\n",
      "Iteration 179: x_k0 = [22.95042439  1.14474643], f(x_k0) = 1.5280835072836885\n",
      "Iteration 180: x_k0 = [-12.70490382  38.25483746], f(x_k0) = 1.742768665493005\n",
      "Iteration 181: x_k0 = [ 40.73631694 -76.05770507], f(x_k0) = 1.9351925190308248\n",
      "Iteration 182: x_k0 = [-37.57514272 -40.54942379], f(x_k0) = 2.678631479276948\n",
      "Iteration 183: x_k0 = [-47.58842867 -12.06886141], f(x_k0) = 1.0404257446492937\n",
      "Iteration 184: x_k0 = [-18.38632453 -40.49477463], f(x_k0) = 2.331800942929328\n",
      "Iteration 185: x_k0 = [ 48.19633547 -83.78846053], f(x_k0) = 2.903983771811915\n",
      "Iteration 186: x_k0 = [-12.29932997  24.2792617 ], f(x_k0) = 1.2917752249183292\n",
      "Iteration 187: x_k0 = [-53.97552158  43.90089791], f(x_k0) = 2.9948582514863076\n",
      "Iteration 188: x_k0 = [-53.25071369 -79.84086369], f(x_k0) = 4.2861141777157155\n",
      "Iteration 189: x_k0 = [82.22571152 49.74770931], f(x_k0) = 4.005525837859613\n",
      "Iteration 190: x_k0 = [-33.82230005   3.17055495], f(x_k0) = 0.8272713855780611\n",
      "Iteration 191: x_k0 = [-12.50342611 -16.05851814], f(x_k0) = 0.7524314294681004\n",
      "Iteration 192: x_k0 = [-2.35500099 58.80494129], f(x_k0) = 1.3446576067608857\n",
      "Iteration 193: x_k0 = [  5.54385077 -29.23809269], f(x_k0) = 1.4071459118290428\n",
      "Iteration 194: x_k0 = [ 33.84952231 -50.66752169], f(x_k0) = 1.703048380466383\n",
      "Iteration 195: x_k0 = [-66.41981404 -38.35370184], f(x_k0) = 2.1056228591119215\n",
      "Iteration 196: x_k0 = [ 81.88032549 -36.22575425], f(x_k0) = 2.135910170080038\n",
      "Iteration 197: x_k0 = [ 11.46215234 -83.88236261], f(x_k0) = 3.2102375708510684\n",
      "Iteration 198: x_k0 = [ 74.95521939 -42.81401565], f(x_k0) = 2.487063816980088\n",
      "Iteration 199: x_k0 = [-66.39587351  65.74035821], f(x_k0) = 2.4501124808458856\n",
      "Iteration 200: x_k0 = [74.87233227 22.71027948], f(x_k0) = 3.3426606036327438\n",
      "Iteration 201: x_k0 = [-44.7275361   10.50910701], f(x_k0) = 1.2261160102436965\n",
      "Iteration 202: x_k0 = [13.88720506  6.16336241], f(x_k0) = 1.1435149913150349\n",
      "Iteration 203: x_k0 = [72.62336465 47.90849542], f(x_k0) = 2.1671218424384064\n",
      "Iteration 204: x_k0 = [-5.73089751 66.85604087], f(x_k0) = 2.9673504636693835\n",
      "Iteration 205: x_k0 = [-51.43119131 -32.09135027], f(x_k0) = 2.2199600445372063\n",
      "Iteration 206: x_k0 = [-58.72082824 -60.91212768], f(x_k0) = 3.136432872116828\n",
      "Iteration 207: x_k0 = [-12.13527627  54.37892307], f(x_k0) = 1.1129453932294222\n",
      "Iteration 208: x_k0 = [-40.61959191   3.1824771 ], f(x_k0) = 0.8018731942688758\n",
      "Iteration 209: x_k0 = [-24.67120341   5.86541793], f(x_k0) = 1.6400960189684266\n",
      "Iteration 210: x_k0 = [-25.26012554  43.27521474], f(x_k0) = 0.9479195373264964\n",
      "Iteration 211: x_k0 = [-35.94134492 -55.29082919], f(x_k0) = 2.1192826593393663\n",
      "Iteration 212: x_k0 = [-48.80713779 -72.16377071], f(x_k0) = 2.816254779086277\n",
      "Iteration 213: x_k0 = [-23.96893226  17.9061231 ], f(x_k0) = 0.8297314882542796\n",
      "Iteration 214: x_k0 = [-44.01552734 -24.01412439], f(x_k0) = 1.9221581032064412\n",
      "Iteration 215: x_k0 = [24.39800359 47.29027913], f(x_k0) = 2.0323610916672123\n",
      "Iteration 216: x_k0 = [-18.49638934  61.44484933], f(x_k0) = 1.2218524535676132\n",
      "Iteration 217: x_k0 = [  5.61353764 -51.74145725], f(x_k0) = 1.3302099007759633\n",
      "Iteration 218: x_k0 = [-46.89304993  -2.26803009], f(x_k0) = 1.5189620259031749\n",
      "Iteration 219: x_k0 = [17.63312469  9.18442493], f(x_k0) = 0.7595342427706986\n",
      "Iteration 220: x_k0 = [28.16782607 -9.1417894 ], f(x_k0) = 2.197333388467455\n",
      "Iteration 221: x_k0 = [63.66701298  3.46352882], f(x_k0) = 2.532849925755421\n",
      "Iteration 222: x_k0 = [-61.00840598 -51.33073483], f(x_k0) = 2.6310142290509773\n",
      "Iteration 223: x_k0 = [  7.59921405 -16.98907269], f(x_k0) = 0.8721740052043873\n",
      "Iteration 224: x_k0 = [40.09059671 54.12864963], f(x_k0) = 2.7480095302851053\n",
      "Iteration 225: x_k0 = [-38.06004051  -9.5097542 ], f(x_k0) = 0.5387820114392781\n",
      "Iteration 226: x_k0 = [-55.74289876  43.4727096 ], f(x_k0) = 1.7090701614113102\n",
      "Iteration 227: x_k0 = [25.43969858 15.11163833], f(x_k0) = 1.5097137217144823\n",
      "Iteration 228: x_k0 = [24.31793764 55.10772333], f(x_k0) = 1.7024499114326854\n",
      "Iteration 229: x_k0 = [  0.30447933 -12.01612592], f(x_k0) = 1.6079122108820125\n",
      "Iteration 230: x_k0 = [-22.00007181 -22.39395061], f(x_k0) = 0.2544600068830095\n",
      "Iteration 231: x_k0 = [ -9.45611853 -14.68126745], f(x_k0) = 0.5000945951422706\n",
      "Iteration 232: x_k0 = [-53.75280262 -10.91270115], f(x_k0) = 1.8811036282560474\n",
      "Iteration 233: x_k0 = [40.73924252 -1.19899365], f(x_k0) = 2.073500204674793\n",
      "Iteration 234: x_k0 = [  3.62213012 -13.7752125 ], f(x_k0) = 0.2078149135543904\n",
      "Iteration 235: x_k0 = [-45.7491483   39.48914984], f(x_k0) = 1.7301895958172187\n",
      "Iteration 236: x_k0 = [-50.32638259 -12.6275106 ], f(x_k0) = 2.551017183211458\n",
      "Iteration 237: x_k0 = [-43.07979311 -58.39972735], f(x_k0) = 2.873437847664028\n",
      "Iteration 238: x_k0 = [-49.61064326 -17.88314609], f(x_k0) = 0.904578763219125\n",
      "Iteration 239: x_k0 = [-21.01548168  12.52008284], f(x_k0) = 0.6781454957751832\n",
      "Iteration 240: x_k0 = [25.20788142 48.65987171], f(x_k0) = 2.7368168529578245\n",
      "Iteration 241: x_k0 = [-20.74303201 -11.61145224], f(x_k0) = 1.0305884963086036\n",
      "Iteration 242: x_k0 = [29.40809381 -5.39845783], f(x_k0) = 0.8932392145182388\n",
      "Iteration 243: x_k0 = [-2.92670988 37.0639829 ], f(x_k0) = 1.8099783438572425\n",
      "Iteration 244: x_k0 = [-26.73327128 -31.74665223], f(x_k0) = 1.403952534064836\n",
      "Iteration 245: x_k0 = [ 25.62603114 -14.08945209], f(x_k0) = 1.9701720798003413\n",
      "Iteration 246: x_k0 = [ 29.35228402 -29.8560645 ], f(x_k0) = 1.1366755816473293\n",
      "Iteration 247: x_k0 = [-25.76634253  -9.2556735 ], f(x_k0) = 0.4089037521471892\n",
      "Iteration 248: x_k0 = [ 36.28080526 -51.27508746], f(x_k0) = 1.9668703750081864\n",
      "Iteration 249: x_k0 = [-28.77908757   9.81269909], f(x_k0) = 1.925045947160081\n",
      "Iteration 250: x_k0 = [48.31224313 40.42447903], f(x_k0) = 1.6366634643195532\n",
      "Iteration 251: x_k0 = [12.13782828 16.08286768], f(x_k0) = 0.7668808359437327\n",
      "Iteration 252: x_k0 = [ 39.36003811 -11.06439454], f(x_k0) = 1.4206327717243692\n",
      "Iteration 253: x_k0 = [-43.72342578  11.15746082], f(x_k0) = 1.543400035983686\n",
      "Iteration 254: x_k0 = [  1.39441743 -18.2205568 ], f(x_k0) = 0.9167879192459027\n",
      "Iteration 255: x_k0 = [40.35400093 13.26843675], f(x_k0) = 0.5680457551882424\n",
      "Iteration 256: x_k0 = [ 16.9785115  -21.79511431], f(x_k0) = 0.9079715269742884\n",
      "Iteration 257: x_k0 = [ 30.18127217 -16.1295651 ], f(x_k0) = 1.161363207622219\n",
      "Iteration 258: x_k0 = [40.63981036 10.34302787], f(x_k0) = 1.94373865281909\n",
      "Iteration 259: x_k0 = [23.37849891  6.67801389], f(x_k0) = 1.1495532930154257\n",
      "Iteration 260: x_k0 = [ 47.52847662 -14.08204786], f(x_k0) = 0.822439902143359\n",
      "Iteration 261: x_k0 = [-11.38646109  21.01717657], f(x_k0) = 1.395281331670699\n",
      "Iteration 262: x_k0 = [-33.68317247 -34.35181621], f(x_k0) = 2.0057085108663046\n",
      "Iteration 263: x_k0 = [-14.91401491  20.80987894], f(x_k0) = 0.7810709038538107\n",
      "Iteration 264: x_k0 = [38.5110294  30.15218149], f(x_k0) = 2.137273701290356\n",
      "Iteration 265: x_k0 = [27.10756094 28.25226086], f(x_k0) = 1.551759923070644\n",
      "Iteration 266: x_k0 = [-30.3933544  -39.63847598], f(x_k0) = 2.1292616195929366\n",
      "Iteration 267: x_k0 = [-27.71799132   6.54523381], f(x_k0) = 1.1313559854338102\n",
      "Iteration 268: x_k0 = [ -3.15199703 -10.1009782 ], f(x_k0) = 1.6809351200225477\n",
      "Iteration 269: x_k0 = [ 10.47857249 -25.08196675], f(x_k0) = 1.402771579705978\n",
      "Iteration 270: x_k0 = [10.38544747 19.36118366], f(x_k0) = 1.3682191816237605\n",
      "Iteration 271: x_k0 = [-12.89069616   1.03173649], f(x_k0) = 0.33519752578352235\n",
      "Iteration 272: x_k0 = [-32.17527218 -13.41302039], f(x_k0) = 2.0277856006375012\n",
      "Iteration 273: x_k0 = [42.25828575 20.73912169], f(x_k0) = 1.4771312026456807\n",
      "Iteration 274: x_k0 = [ 33.63436784 -40.88278961], f(x_k0) = 1.2146614954096373\n",
      "Iteration 275: x_k0 = [ 24.78118504 -38.1731924 ], f(x_k0) = 1.7853750575112275\n",
      "Iteration 276: x_k0 = [37.53670307 16.44867471], f(x_k0) = 0.8342051715557507\n",
      "Iteration 277: x_k0 = [-0.47771221 24.30159389], f(x_k0) = 1.231881717487221\n",
      "Iteration 278: x_k0 = [13.06821614 -4.60265364], f(x_k0) = 1.919098110081946\n",
      "Iteration 279: x_k0 = [ 24.1011437  -33.97824025], f(x_k0) = 1.2039260935819867\n",
      "Iteration 280: x_k0 = [-30.9214295   20.38919237], f(x_k0) = 1.5863569825311326\n",
      "Iteration 281: x_k0 = [19.41402498 14.48962332], f(x_k0) = 1.7225269440071773\n",
      "Iteration 282: x_k0 = [-28.99543554  15.95436269], f(x_k0) = 1.48561316083775\n",
      "Iteration 283: x_k0 = [ 26.85013664 -20.50792936], f(x_k0) = 1.2333539160371372\n",
      "Iteration 284: x_k0 = [ 22.8812835  -36.56554376], f(x_k0) = 1.9370166432236546\n",
      "Iteration 285: x_k0 = [-20.73790505   1.93013663], f(x_k0) = 1.1723095526112755\n",
      "Iteration 286: x_k0 = [22.68904711  2.50143143], f(x_k0) = 0.979558263252597\n",
      "Iteration 287: x_k0 = [-8.94638446 28.49819926], f(x_k0) = 1.4590480268031834\n",
      "Iteration 288: x_k0 = [-15.94919772  24.41535569], f(x_k0) = 1.1985458472402408\n",
      "Iteration 289: x_k0 = [31.20614659 29.11255441], f(x_k0) = 1.6163131715477435\n",
      "Iteration 290: x_k0 = [ -2.17261814 -30.97704558], f(x_k0) = 0.6770739121273615\n",
      "Iteration 291: x_k0 = [-12.6984745  -36.42303492], f(x_k0) = 0.5664736724194257\n",
      "Iteration 292: x_k0 = [ -2.91686681 -19.9898392 ], f(x_k0) = 1.1041858094880161\n",
      "Iteration 293: x_k0 = [ 8.74417606 -9.40315899], f(x_k0) = 1.7669788085061984\n",
      "Iteration 294: x_k0 = [ 4.22157003 16.95505422], f(x_k0) = 1.4712756722362694\n",
      "Iteration 295: x_k0 = [ 22.23427055 -16.67903722], f(x_k0) = 1.8882376991383953\n",
      "Iteration 296: x_k0 = [-5.39727687 -2.66602074], f(x_k0) = 1.2046632288008083\n",
      "Iteration 297: x_k0 = [11.71597211 20.8657654 ], f(x_k0) = 1.524932650742741\n",
      "Iteration 298: x_k0 = [27.88753975 26.53736093], f(x_k0) = 2.2932812076693505\n",
      "Iteration 299: x_k0 = [-26.11668834 -29.58164676], f(x_k0) = 1.6533219057942075\n",
      "Iteration 300: x_k0 = [-12.79632434 -14.31280679], f(x_k0) = 1.8394223092557536\n",
      "Iteration 301: x_k0 = [  0.9224144  -10.38070051], f(x_k0) = 0.7303859567738291\n",
      "Iteration 302: x_k0 = [ 10.27569864 -19.33391495], f(x_k0) = 1.4160923711201043\n",
      "Iteration 303: x_k0 = [ 5.55193224 21.38217627], f(x_k0) = 1.7411343884384571\n",
      "Iteration 304: x_k0 = [21.71365969 13.56297478], f(x_k0) = 0.21528483081969219\n",
      "Iteration 305: x_k0 = [-17.38679398  17.90278752], f(x_k0) = 1.048342316740063\n",
      "Iteration 306: x_k0 = [ 28.76922521 -19.79488613], f(x_k0) = 1.427737122798753\n",
      "Iteration 307: x_k0 = [-9.47062651 11.82166661], f(x_k0) = 0.5738881587337133\n",
      "Iteration 308: x_k0 = [ 0.55561169 15.18983161], f(x_k0) = 1.2718494189331535\n",
      "Iteration 309: x_k0 = [ 6.62146766 23.77668757], f(x_k0) = 1.5762320008089228\n",
      "Iteration 310: x_k0 = [26.04337569 15.16458325], f(x_k0) = 1.3921600927753333\n",
      "Iteration 311: x_k0 = [-15.17328336   3.95513921], f(x_k0) = 0.2517037777957013\n",
      "Iteration 312: x_k0 = [ 30.49295506 -18.80857937], f(x_k0) = 0.8725495589966006\n",
      "Iteration 313: x_k0 = [-11.70689665 -28.02939823], f(x_k0) = 0.8617461108771878\n",
      "Iteration 314: x_k0 = [-23.04441377 -28.69235451], f(x_k0) = 1.403588610395938\n",
      "Iteration 315: x_k0 = [ 30.03592322 -15.43908088], f(x_k0) = 1.3000008906887262\n",
      "Iteration 316: x_k0 = [22.3795926  -8.77712795], f(x_k0) = 2.0672411495302403\n",
      "Iteration 317: x_k0 = [-22.8394365  -21.21902873], f(x_k0) = 0.7388471176222642\n",
      "Iteration 318: x_k0 = [-14.62215602  -0.69302442], f(x_k0) = 1.464905084879676\n",
      "Iteration 319: x_k0 = [6.75122725 1.39821278], f(x_k0) = 0.5212232433286106\n",
      "Iteration 320: x_k0 = [-18.87105048  10.89433764], f(x_k0) = 0.9687815538669431\n",
      "Iteration 321: x_k0 = [-14.22534265   4.30901153], f(x_k0) = 0.9675647524738249\n",
      "Iteration 322: x_k0 = [-18.51156641  -9.00935225], f(x_k0) = 0.16613846978345792\n",
      "Iteration 323: x_k0 = [-10.53521606  15.69957918], f(x_k0) = 1.1362407760572064\n",
      "Iteration 324: x_k0 = [27.10940446  8.04198133], f(x_k0) = 1.526499439666018\n",
      "Iteration 325: x_k0 = [ 10.051223  -24.4032452], f(x_k0) = 1.1554571911185936\n",
      "Iteration 326: x_k0 = [-13.16785698  -7.99474177], f(x_k0) = 0.39313598687288354\n",
      "Iteration 327: x_k0 = [ 18.13673862 -18.42815756], f(x_k0) = 0.4907027262584225\n",
      "Global Minimum:\n",
      "f(x_ast) =  0.0\n",
      "x_ast =  [-7.70909064e-09 -1.16094638e-08]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def griewank(x):\n",
    "    return griewank_(x[0], x[1])\n",
    "\n",
    "def griewank_(x1, x2):\n",
    "    A = x1**2 / 4000 + x2**2 / 4000\n",
    "    B = np.cos(x1 / np.sqrt(1)) * np.cos(x2 / np.sqrt(2))\n",
    "    return A - B + 1\n",
    "\n",
    "def refined_global_optimizer(bounds, tau, K_warmup, K_max):\n",
    "    x_ast = None\n",
    "\n",
    "    for k in range(K_max):\n",
    "        x_k = np.random.uniform(bounds[0], bounds[1], size=2)\n",
    "\n",
    "        if k >= K_warmup:\n",
    "            chi_k = 0.50 * 2 / (1 + np.exp((k - K_warmup) / 100))\n",
    "            x_k0 = chi_k * x_k + (1 - chi_k) * x_ast\n",
    "        else:\n",
    "            x_k0 = x_k\n",
    "\n",
    "        result = minimize(griewank, x_k0, method='BFGS', tol=tau)\n",
    "        x_k_ast = result.x\n",
    "\n",
    "        if x_ast is None or griewank(x_k_ast) < griewank(x_ast):\n",
    "            x_ast = x_k_ast\n",
    "\n",
    "        if griewank(x_ast) < tau:\n",
    "            break\n",
    "\n",
    "        print(f\"Iteration {k}: x_k0 = {x_k0}, f(x_k0) = {griewank(x_k0)}\")\n",
    "\n",
    "    return x_ast\n",
    "\n",
    "# Set the settings\n",
    "bounds = [-600, 600]\n",
    "tau = 1e-8\n",
    "K_warmup = 10\n",
    "K_max = 1000\n",
    "\n",
    "# Run the optimizer\n",
    "global_optimum = refined_global_optimizer(bounds, tau, K_warmup, K_max)\n",
    "\n",
    "print(\"Global Minimum:\")\n",
    "print(\"f(x_ast) = \", griewank(global_optimum))\n",
    "print(\"x_ast = \", global_optimum)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Is it a better idea to set $\\underline{K} = 100$? Is the convergence faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: x_k0 = [-515.37027881 -432.51783266], f(x_k0) = 114.61652304744635\n",
      "Iteration 1: x_k0 = [-27.34194113 132.87288971], f(x_k0) = 6.171307150313673\n",
      "Iteration 2: x_k0 = [ 55.49847472 508.24780356], f(x_k0) = 66.18926150628722\n",
      "Iteration 3: x_k0 = [ -6.58781124 372.54031222], f(x_k0) = 34.85603952188753\n",
      "Iteration 4: x_k0 = [ 474.39217104 -472.92255025], f(x_k0) = 113.34792143201386\n",
      "Iteration 5: x_k0 = [-167.27324293 -142.12599455], f(x_k0) = 13.763372623891525\n",
      "Iteration 6: x_k0 = [ 203.3196042  -422.96350485], f(x_k0) = 55.54650468056858\n",
      "Iteration 7: x_k0 = [424.17251216 225.11696501], f(x_k0) = 58.14417186405112\n",
      "Iteration 8: x_k0 = [  -2.24006381 -143.82319296], f(x_k0) = 6.416076886008673\n",
      "Iteration 9: x_k0 = [-536.31761712 -130.74040676], f(x_k0) = 77.04002833013499\n",
      "Iteration 10: x_k0 = [-309.49180132 -205.81905909], f(x_k0) = 35.56006244846056\n",
      "Iteration 11: x_k0 = [114.03424221 288.43901555], f(x_k0) = 25.624621773076967\n",
      "Iteration 12: x_k0 = [218.57597984  98.55964857], f(x_k0) = 15.177002757009696\n",
      "Iteration 13: x_k0 = [ 103.41998298 -138.23623357], f(x_k0) = 7.544491775937151\n",
      "Iteration 14: x_k0 = [108.26520075 -91.44943369], f(x_k0) = 6.052014239318633\n",
      "Iteration 15: x_k0 = [-113.00599674  233.05905687], f(x_k0) = 17.636728725265282\n",
      "Iteration 16: x_k0 = [-37.02827051 311.48049574], f(x_k0) = 24.85894438392312\n",
      "Iteration 17: x_k0 = [-113.00975177  -64.87845865], f(x_k0) = 5.561210666896775\n",
      "Iteration 18: x_k0 = [ 130.22994059 -251.93530731], f(x_k0) = 21.020232876324137\n",
      "Iteration 19: x_k0 = [  4.77354155 190.12416925], f(x_k0) = 10.091134237077572\n",
      "Iteration 20: x_k0 = [-211.44961251   41.48007043], f(x_k0) = 12.326930748683644\n",
      "Iteration 21: x_k0 = [ -88.780751   -131.75326787], f(x_k0) = 6.989874400013654\n",
      "Iteration 22: x_k0 = [216.78846375 166.56938585], f(x_k0) = 19.658275485894798\n",
      "Iteration 23: x_k0 = [-181.17948494  197.4442226 ], f(x_k0) = 18.857445282707126\n",
      "Iteration 24: x_k0 = [-115.03263712  119.95347166], f(x_k0) = 7.548850334938584\n",
      "Iteration 25: x_k0 = [ -18.3895577  -197.66864791], f(x_k0) = 10.827652922799157\n",
      "Iteration 26: x_k0 = [-31.94609051 158.23161865], f(x_k0) = 7.210444065524115\n",
      "Iteration 27: x_k0 = [-43.40746209 227.67427145], f(x_k0) = 15.033177963678934\n",
      "Iteration 28: x_k0 = [  45.08960058 -144.70579904], f(x_k0) = 6.841076400427017\n",
      "Iteration 29: x_k0 = [-48.77742501  80.16281473], f(x_k0) = 3.1194359844512594\n",
      "Iteration 30: x_k0 = [178.6469858    0.47726393], f(x_k0) = 9.8388612994121\n",
      "Iteration 31: x_k0 = [-267.60304649   44.65308956], f(x_k0) = 20.23389882322233\n",
      "Iteration 32: x_k0 = [-197.94991439 -170.47319297], f(x_k0) = 18.458439901506345\n",
      "Iteration 33: x_k0 = [-159.35232019  108.44178036], f(x_k0) = 10.472268368539678\n",
      "Iteration 34: x_k0 = [ 96.32106598 160.9311653 ], f(x_k0) = 10.163065231540406\n",
      "Iteration 35: x_k0 = [181.95109081  50.72391474], f(x_k0) = 10.169152614784293\n",
      "Iteration 36: x_k0 = [80.84178101 62.08368905], f(x_k0) = 2.9319757906894797\n",
      "Iteration 37: x_k0 = [206.3079264 241.9562249], f(x_k0) = 26.21155945872592\n",
      "Iteration 38: x_k0 = [80.66806621 26.04943784], f(x_k0) = 2.31557082888005\n",
      "Iteration 39: x_k0 = [272.89639406 -30.62441694], f(x_k0) = 18.99150547078009\n",
      "Iteration 40: x_k0 = [  63.65016076 -219.68640945], f(x_k0) = 14.192031280872019\n",
      "Iteration 41: x_k0 = [ -55.37455384 -125.11498522], f(x_k0) = 5.3419035877058425\n",
      "Iteration 42: x_k0 = [-179.56477442  266.00166919], f(x_k0) = 27.559674700984623\n",
      "Iteration 43: x_k0 = [157.46039787 -64.05979013], f(x_k0) = 7.989297071199814\n",
      "Iteration 44: x_k0 = [-77.2511381  142.71927365], f(x_k0) = 7.841955599494842\n",
      "Iteration 45: x_k0 = [ 9.13653652 31.68886067], f(x_k0) = 0.3950392517994291\n",
      "Iteration 46: x_k0 = [204.9750355  181.25313473], f(x_k0) = 19.14186901848171\n",
      "Iteration 47: x_k0 = [184.06672293 138.23583579], f(x_k0) = 13.985407627738127\n",
      "Iteration 48: x_k0 = [ -11.60743417 -134.89962027], f(x_k0) = 5.34364030231189\n",
      "Iteration 49: x_k0 = [-45.07977339  30.05589705], f(x_k0) = 2.0709973343464774\n",
      "Iteration 50: x_k0 = [-220.80183672  -23.63875976], f(x_k0) = 13.664184547539275\n",
      "Iteration 51: x_k0 = [216.6338121  171.62422402], f(x_k0) = 19.70558909653881\n",
      "Iteration 52: x_k0 = [ 92.38839544 140.9699628 ], f(x_k0) = 8.289835178598118\n",
      "Iteration 53: x_k0 = [185.99537157 210.00754071], f(x_k0) = 20.141286200148173\n",
      "Iteration 54: x_k0 = [-73.87512171 -16.87058031], f(x_k0) = 2.397213294632539\n",
      "Iteration 55: x_k0 = [ 162.72438213 -214.56897565], f(x_k0) = 18.647587325274337\n",
      "Iteration 56: x_k0 = [-117.87915932  117.87996123], f(x_k0) = 7.954826261823796\n",
      "Iteration 57: x_k0 = [ 148.42108148 -172.81623766], f(x_k0) = 13.290199671753625\n",
      "Iteration 58: x_k0 = [102.8394374   82.48404144], f(x_k0) = 5.207609221898496\n",
      "Iteration 59: x_k0 = [-215.40746714  203.10544625], f(x_k0) = 23.042282948140855\n",
      "Iteration 60: x_k0 = [-91.49224606 227.00607344], f(x_k0) = 15.089618674188609\n",
      "Iteration 61: x_k0 = [-168.27561978 -123.05306187], f(x_k0) = 11.749363683914291\n",
      "Iteration 62: x_k0 = [117.02906388 -39.09949766], f(x_k0) = 4.236176564605597\n",
      "Iteration 63: x_k0 = [42.35291903 81.74902881], f(x_k0) = 3.1372614617544587\n",
      "Iteration 64: x_k0 = [194.85243142 225.64004695], f(x_k0) = 24.002156348622567\n",
      "Iteration 65: x_k0 = [-114.26625513  116.9909399 ], f(x_k0) = 7.489150125923755\n",
      "Iteration 66: x_k0 = [-106.87396081  -78.69214345], f(x_k0) = 4.786979964730877\n",
      "Iteration 67: x_k0 = [ 59.06231426 104.12408541], f(x_k0) = 4.4213148423297035\n",
      "Iteration 68: x_k0 = [53.60031437 16.07987535], f(x_k0) = 2.1419922797172535\n",
      "Iteration 69: x_k0 = [  22.86356948 -140.94716546], f(x_k0) = 6.513649422410353\n",
      "Iteration 70: x_k0 = [-49.06147757 -76.82030966], f(x_k0) = 3.2963249412145963\n",
      "Iteration 71: x_k0 = [ 27.01719213 141.41729516], f(x_k0) = 6.447802522614465\n",
      "Iteration 72: x_k0 = [  52.50544891 -174.22259496], f(x_k0) = 8.792070661537519\n",
      "Iteration 73: x_k0 = [-155.13978494    9.4823761 ], f(x_k0) = 7.368671239248085\n",
      "Iteration 74: x_k0 = [-186.75923875  -80.19096518], f(x_k0) = 11.490197384510966\n",
      "Iteration 75: x_k0 = [-70.02230312 -36.09795359], f(x_k0) = 1.982447825736863\n",
      "Iteration 76: x_k0 = [-91.5937819  -33.66272976], f(x_k0) = 3.5916806048523333\n",
      "Iteration 77: x_k0 = [ 97.70609994 194.09465889], f(x_k0) = 13.330621596022713\n",
      "Iteration 78: x_k0 = [179.86986061 142.28076756], f(x_k0) = 14.84456083579893\n",
      "Iteration 79: x_k0 = [-176.97658271  188.87546443], f(x_k0) = 17.76736918878422\n",
      "Iteration 80: x_k0 = [  96.40246242 -171.71391897], f(x_k0) = 10.445723204442873\n",
      "Iteration 81: x_k0 = [25.23315225  6.43527086], f(x_k0) = 1.329977034050834\n",
      "Iteration 82: x_k0 = [ 170.88996412 -104.24518517], f(x_k0) = 11.054432833150809\n",
      "Iteration 83: x_k0 = [207.97857492 136.62500001], f(x_k0) = 17.052839682908413\n",
      "Iteration 84: x_k0 = [-81.97856598 165.29104319], f(x_k0) = 10.27763720786964\n",
      "Iteration 85: x_k0 = [ 44.55280692 -48.46732922], f(x_k0) = 2.8909613638033287\n",
      "Iteration 86: x_k0 = [203.6359188  -46.24196646], f(x_k0) = 12.141550644276991\n",
      "Iteration 87: x_k0 = [-155.71337941 -103.53168275], f(x_k0) = 9.859298953964396\n",
      "Iteration 88: x_k0 = [-20.08463065 156.28573814], f(x_k0) = 7.487162802614241\n",
      "Iteration 89: x_k0 = [ 95.930519 104.02349 ], f(x_k0) = 5.975907031369584\n",
      "Iteration 90: x_k0 = [194.51166731 120.01397152], f(x_k0) = 15.023322217586676\n",
      "Iteration 91: x_k0 = [145.9351038   -7.34538421], f(x_k0) = 6.269014086823308\n",
      "Iteration 92: x_k0 = [-146.29480447   98.34394774], f(x_k0) = 8.959036787557636\n",
      "Iteration 93: x_k0 = [ 149.65124503 -157.7585802 ], f(x_k0) = 12.8102387346212\n",
      "Iteration 94: x_k0 = [ 14.39775887 180.86221244], f(x_k0) = 9.072781181263842\n",
      "Iteration 95: x_k0 = [128.00270399 -50.19911146], f(x_k0) = 5.315572769060853\n",
      "Iteration 96: x_k0 = [ -3.88279113 -16.55945834], f(x_k0) = 1.5552383911717205\n",
      "Iteration 97: x_k0 = [-52.85451071  66.40778085], f(x_k0) = 1.9614875925968174\n",
      "Iteration 98: x_k0 = [127.39466214  23.51557983], f(x_k0) = 5.098989887763869\n",
      "Iteration 99: x_k0 = [ 77.75258586 142.11352944], f(x_k0) = 8.2656314943442\n",
      "Global Minimum:\n",
      "f(x_ast) =  0.08874262788901788\n",
      "x_ast =  [ -6.28004504 -17.75377744]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def griewank(x):\n",
    "    return griewank_(x[0], x[1])\n",
    "\n",
    "def griewank_(x1, x2):\n",
    "    A = x1**2 / 4000 + x2**2 / 4000\n",
    "    B = np.cos(x1 / np.sqrt(1)) * np.cos(x2 / np.sqrt(2))\n",
    "    return A - B + 1\n",
    "\n",
    "def refined_global_optimizer(bounds, tau, K_warmup, K_max):\n",
    "    x_ast = None\n",
    "\n",
    "    for k in range(K_max):\n",
    "        x_k = np.random.uniform(bounds[0], bounds[1], size=2)\n",
    "\n",
    "        if k >= K_warmup:\n",
    "            chi_k = 0.50 * 2 / (1 + np.exp((k - K_warmup) / 100))\n",
    "            x_k0 = chi_k * x_k + (1 - chi_k) * x_ast\n",
    "        else:\n",
    "            x_k0 = x_k\n",
    "\n",
    "        result = minimize(griewank, x_k0, method='BFGS', tol=tau)\n",
    "        x_k_ast = result.x\n",
    "\n",
    "        if x_ast is None or griewank(x_k_ast) < griewank(x_ast):\n",
    "            x_ast = x_k_ast\n",
    "\n",
    "        if griewank(x_ast) < tau:\n",
    "            break\n",
    "\n",
    "        print(f\"Iteration {k}: x_k0 = {x_k0}, f(x_k0) = {griewank(x_k0)}\")\n",
    "\n",
    "    return x_ast\n",
    "\n",
    "# Set the settings\n",
    "bounds = [-600, 600]\n",
    "tau = 1e-8\n",
    "K_warmup = 10\n",
    "K_max = 100  # Set K_max to 100\n",
    "\n",
    "# Run the optimizer\n",
    "global_optimum = refined_global_optimizer(bounds, tau, K_warmup, K_max)\n",
    "\n",
    "print(\"Global Minimum:\")\n",
    "print(\"f(x_ast) = \", griewank(global_optimum))\n",
    "print(\"x_ast = \", global_optimum)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a51ff870275167439250c661bd9e1549ea6d98969bbf5f9ab16d16cab496595"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
